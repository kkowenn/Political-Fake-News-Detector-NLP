{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFQkzE-jd-NZ",
        "outputId": "68341f83-eba2-43d9-9ced-9e1d11c14730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                               title  \\\n",
            "0  law enforcement high alert following threat co...   \n",
            "1                                            missing   \n",
            "2  unbelievable obamas attorney general say charl...   \n",
            "3  bobby jindal raised hindu us story christian c...   \n",
            "4  satan 2 russia unvelis image terrifying new su...   \n",
            "\n",
            "                                                text  label  title_missing  \\\n",
            "0  comment expected barack obama member fyf911 fu...      1          False   \n",
            "1                          post vote hillary already      1           True   \n",
            "2  demonstrator gathered last night exercising co...      1          False   \n",
            "3  dozen politically active pastor came private d...      0          False   \n",
            "4  rs28 sarmat missile dubbed satan 2 replace ss1...      1          False   \n",
            "\n",
            "   text_missing                                       title_tokens  \\\n",
            "0         False  ['law', 'enforcement', 'high', 'alert', 'follo...   \n",
            "1         False                                        ['missing']   \n",
            "2         False  ['unbelievable', 'obamas', 'attorney', 'genera...   \n",
            "3         False  ['bobby', 'jindal', 'raised', 'hindu', 'uses',...   \n",
            "4         False  ['satan', '2', 'russia', 'unvelis', 'image', '...   \n",
            "\n",
            "                                         text_tokens  \\\n",
            "0  ['comment', 'expected', 'barack', 'obama', 'me...   \n",
            "1            ['post', 'votes', 'hillary', 'already']   \n",
            "2  ['demonstrators', 'gathered', 'last', 'night',...   \n",
            "3  ['dozen', 'politically', 'active', 'pastors', ...   \n",
            "4  ['rs28', 'sarmat', 'missile', 'dubbed', 'satan...   \n",
            "\n",
            "                                back_translated_text  \n",
            "0  Wait for comments barack obama, members, fyf91...  \n",
            "1                                  Voted for Hillary  \n",
            "2  Protesters gathered last night to exercise the...  \n",
            "3  dozen politically active pastor came private d...  \n",
            "4  The rs28 sarmat missile is called the satan 2 ...  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "backtranslate = '/content/drive/MyDrive/deeplearningProgression/backtranslate.csv'\n",
        "backtranslate = pd.read_csv(backtranslate)\n",
        "\n",
        "print(backtranslate.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remove any unnamed columns (if present)\n",
        "backtranslate = backtranslate.loc[:, ~backtranslate.columns.str.contains('^Unnamed')]"
      ],
      "metadata": {
        "id": "cX0-jPu6rJoa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Handle missing values for `back_translated_text`\n",
        "backtranslate['back_translated_text_missing'] = backtranslate['back_translated_text'].isna() | backtranslate['back_translated_text'].eq('')\n",
        "backtranslate['back_translated_text'] = backtranslate['back_translated_text'].replace('', 'missing')\n",
        "backtranslate['back_translated_text'] = backtranslate['back_translated_text'].fillna('missing')"
      ],
      "metadata": {
        "id": "76HEV9bBeV7F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Convert all text in `back_translated_text` to lowercase\n",
        "backtranslate['back_translated_text'] = backtranslate['back_translated_text'].str.lower()"
      ],
      "metadata": {
        "id": "0J3FPo5cgQRB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "# 4. Remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    return text\n",
        "\n",
        "backtranslate['back_translated_text'] = backtranslate['back_translated_text'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "jSQMAyZ7jHN5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK models and corpora\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFB90CrurkXP",
        "outputId": "6d503589-c4eb-4f5b-db95-f98ddaf82892"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# 5. Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_text)\n",
        "\n",
        "backtranslate['back_translated_text'] = backtranslate['back_translated_text'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "90VpHtC-rRqK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Tokenization\n",
        "def tokenize_text(text):\n",
        "    return [word for word in word_tokenize(text) if word.isalnum()]\n",
        "\n",
        "# Create a new column for tokenized text\n",
        "backtranslate['back_translated_text_tokens'] = backtranslate['back_translated_text'].apply(tokenize_text)"
      ],
      "metadata": {
        "id": "VkqoTp1QuCan"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "# 7. Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word.lower()) for word in word_tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "backtranslate['back_translated_text'] = backtranslate['back_translated_text'].apply(lemmatize_text)\n"
      ],
      "metadata": {
        "id": "reAgaMDarsBT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save and check"
      ],
      "metadata": {
        "id": "YxGpNvMrr2vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the processed dataset to a new CSV file\n",
        "backtranslate.to_csv('backtranslate_processed.csv', index=False)\n",
        "\n",
        "# Check the quality of the cleaned dataset\n",
        "print(\"\\nProcessed Data:\")\n",
        "print(backtranslate[['back_translated_text', 'back_translated_text_tokens']].head())\n",
        "\n",
        "# Print the lengths\n",
        "print(f\"\\nTotal number of rows: {len(backtranslate)}\")\n",
        "print(f\"Length of tokenized text column: {backtranslate['back_translated_text_tokens'].apply(len).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLnPWSKMrfQf",
        "outputId": "28c893e7-b10e-4910-d86b-dc24760dccad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed Data:\n",
            "                                back_translated_text  \\\n",
            "0  wait comment barack obama member fyf911 fukyof...   \n",
            "1                                      voted hillary   \n",
            "2  protester gathered last night exercise constit...   \n",
            "3  dozen politically active pastor came private d...   \n",
            "4  rs28 sarmat missile called satan 2 replaces ss...   \n",
            "\n",
            "                         back_translated_text_tokens  \n",
            "0  [wait, comment, barack, obama, member, fyf911,...  \n",
            "1                                   [voted, hillary]  \n",
            "2  [protester, gathered, last, night, exercise, c...  \n",
            "3  [dozen, politically, active, pastor, came, pri...  \n",
            "4  [rs28, sarmat, missile, called, satan, 2, repl...  \n",
            "\n",
            "Total number of rows: 29995\n",
            "Length of tokenized text column: 8654262\n"
          ]
        }
      ]
    }
  ]
}